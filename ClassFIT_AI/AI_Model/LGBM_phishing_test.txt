from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, roc_auc_score
import pandas as pd
import numpy as np

dataset = pd.read_csv('phishing.csv')
features = np.array(dataset.iloc[:, 1:-1].values)
label = np.array(dataset.iloc[:, -1].values)

x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.2, shuffle=True, random_state=156)

# #애림님 : 0.94...
# #트리개수는 400개로 지정
# lgbm_wrapper = LGBMClassifier(n_estimaors =400)
# evals = [(x_test, y_test)]
# lgbm_wrapper.fit(x_train, y_train, early_stopping_rounds= 100, eval_metric='logloss',
#                 eval_set =evals, verbose = True)
# preds = lgbm_wrapper.predict(x_test)
# accuracy = accuracy_score(y_test, preds)
# precision = precision_score(y_test, preds)
# AUC = roc_auc_score(y_test, preds)
# print('\n정확도: {:.4f}'.format(accuracy))
# print('정밀도: {:.4f}'.format(precision))
# print('AUC: {:.4f}'.format(AUC))

# # 지연님 : 0.94...
# clf = LGBMClassifier(boosting_type='gbdt', learning_rate=0.03, 
#                n_estimators=400, objective='binary', metric='binary_logloss')
# clf.fit(x_train, y_train)
# y_pred = clf.predict(x_test)
# #accuracy : normalize=True이면 올바르게 분류된 데이터 비율 출력
# print(accuracy_score(y_test, y_pred, normalize=True))
