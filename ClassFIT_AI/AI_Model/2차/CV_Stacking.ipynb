{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7565, 11) (7565,)\n",
      "(3168, 10) (3168,)\n",
      "DecisionTreeClassifier 모델 시작\n",
      "Fold 횟수 : 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 11 and input n_features is 10 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a7e0c1019ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_fold_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mtrain_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stacking_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mtrain_knn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stacking_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_knn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mtrain_forest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_stacking_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_forest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-a7e0c1019ca3>\u001b[0m in \u001b[0;36mget_stacking_datasets\u001b[0;34m(model, x_train_n, y_train_n, x_test_n, n_folds)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtrain_fold_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtest_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolder_counter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mtest_pred_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \"\"\"\n\u001b[1;32m    426\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[1;32m    397\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 11 and input n_features is 10 "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# #dataset\n",
    "# train_dataset = pd.read_csv('ld1.csv')\n",
    "# X_train = np.array(train_dataset.iloc[:, 1:-1].values)\n",
    "# y_train = np.array(train_dataset.iloc[:, -1].values)\n",
    "\n",
    "# test_dataset = pd.read_csv('ld2.csv')\n",
    "# test_dataset['label']=np.nan\n",
    "# X_test = np.array(test_dataset.iloc[:, 1:-1].values)\n",
    "# y_test = np.array(test_dataset.iloc[:, -1].values)\n",
    "\n",
    "dataset = pd.read_csv('ld1.csv')\n",
    "X_train = np.array(dataset.iloc[:, 1:-1].values)\n",
    "y_train = np.array(dataset.iloc[:, -1].values)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "test_dataset = pd.read_csv('ld2.csv')\n",
    "#test_dataset['label']=np.nan\n",
    "# new_X_test = np.array(test_dataset.iloc[:, 1:-1].values)\n",
    "X_test = np.array(test_dataset.iloc[:, 1:-1].values)\n",
    "y_test = np.array(test_dataset.iloc[:, -1].values)\n",
    "# y_test = np.array(test_dataset.iloc[:, -1].values)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_data, y_label)\n",
    "\n",
    "#LogisticRegression()\n",
    "#model_logistic = LogisticRegression()\n",
    "#model_logistic.fit(X_train, y_train)\n",
    "\n",
    "#RandomForest\n",
    "model_forest = RandomForestClassifier(n_estimators=10)\n",
    "model_forest.fit(X_train, y_train)\n",
    "\n",
    "#KNN\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(X_train, y_train)\n",
    "\n",
    "#DecisionTree\n",
    "model_dt = DecisionTreeClassifier(random_state=0)\n",
    "model_dt.fit(X_train, y_train)\n",
    "\n",
    "lr_final = LogisticRegression(C=10)\n",
    "\n",
    "\n",
    "def get_stacking_datasets(model, x_train_n, y_train_n, x_test_n, n_folds) :\n",
    "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=42)\n",
    "    \n",
    "    train_fold_pred = np.zeros((x_train_n.shape[0], 1))\n",
    "    test_pred = np.zeros((x_test_n.shape[0], n_folds))\n",
    "    print(model.__class__.__name__, '모델 시작')\n",
    "    \n",
    "    for folder_counter, (train_idx, valid_idx) in enumerate(kf.split(x_train_n)) :\n",
    "        print(f\"Fold 횟수 : {folder_counter + 1}\")\n",
    "        x_tr = x_train_n[train_idx]\n",
    "        y_tr = y_train_n[train_idx]\n",
    "        x_te = x_train_n[valid_idx]\n",
    "        \n",
    "        model.fit(x_tr, y_tr)\n",
    "        train_fold_pred[valid_idx, :] = model.predict(x_te).reshape(-1, 1)\n",
    "        test_pred[:, folder_counter] = model.predict(x_test_n)\n",
    "    \n",
    "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1, 1)\n",
    "    \n",
    "    return train_fold_pred, test_pred_mean\n",
    "\n",
    "train_dt, test_dt = get_stacking_datasets(model_dt, X_train, y_train, X_test, 5)\n",
    "train_knn, test_knn = get_stacking_datasets(model_knn, X_train, y_train, X_test, 5)\n",
    "train_forest, test_forest = get_stacking_datasets(model_forest, X_train, y_train, X_test, 5)\n",
    "\n",
    "stack_final_x_train = np.concatenate((train_dt, train_knn, train_forest), axis=1)\n",
    "print(stack_final_x_train)\n",
    "print(stack_final_x_train.shape)\n",
    "stack_final_x_test = np.concatenate((test_dt, test_knn, test_forest), axis=1)\n",
    "print(stack_final_x_test.shape)\n",
    "print(stack_final_x_test)\n",
    "#df = pd.DataFrame(stack_final_x_test)\n",
    "#df.to_csv('aaa.csv')\n",
    "\n",
    "\n",
    "lr_final.fit(stack_final_x_train, y_train)\n",
    "stack_final_pred = lr_final.predict(stack_final_x_test)\n",
    "print(stack_final_pred.shape)\n",
    "print(stack_final_pred)\n",
    "\n",
    "test_dataset['label']=stack_final_pred\n",
    "result_dataset = test_dataset[['url','label']]\n",
    "# df = pd.DataFrame(test_dataset[['url'],], stack_final_pred)\n",
    "result_dataset.to_csv('aaa.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
